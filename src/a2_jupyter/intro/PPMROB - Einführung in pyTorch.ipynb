{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516a8a94",
   "metadata": {},
   "source": [
    "# PPMROB - Laborübung\n",
    "Dr. Dietmar Schreiner\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9be6f",
   "metadata": {},
   "source": [
    "# Einführung in pyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f46ed3",
   "metadata": {},
   "source": [
    "## Tensoren\n",
    "\n",
    "* Ein Tensor ist ein n-dimensionales Array (in der Mathematik n-dimensionaler Tensor)\n",
    "* In pyTorch ist ein Tensor eine Instanz der Klasse *torch.tensor*.\n",
    "\n",
    "### Rank, Axes und Shape\n",
    "\n",
    "#### Rank\n",
    "Der Rang (rank) eines Tensors gibt die Anzahl der Dimensionen des Tensors an. D.h. der Rang gibt an, wieviele Indizes zur Adressierung von Elementen des Tensors benötigt werden.\n",
    "\n",
    "__Beispiel__: Ein rank-2 Tensor\n",
    "* ist eine Matrix\n",
    "* ist ein 2d-Array\n",
    "* ist ein 2d-Tensor\n",
    "\n",
    "#### Axes\n",
    "Eine Achse ist eine spezifische Dimension des Tensors.Für jede Achse existiert ein Index zur Adressierung der Elemente des Tensors. Ein rank-2 Tensor hat also 2 Dimensionen und damit 2 Achsen und somit 2 Indizes. \n",
    "\n",
    "Achsen besitzen eine spezifische Länge (length), wodurch der Gültigkeitsbereich der Indizes wie auch der Speicherverbrauch des Tensors bekannt ist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c54c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python matrix (allgemein)\n",
    "\n",
    "td = [\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6697aa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244395f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983a311b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4c4ac",
   "metadata": {},
   "source": [
    "#### Shape\n",
    "\n",
    "Die Shape eines Tensors gibt die konkrete Ausformung eines Tensors wieder. Sie enthält die vollständige Information zu den Achsen, dem Rang und damit den Indizes. \n",
    "\n",
    "In pyTorch werden die Begriffe __size__ und __shape__ für Tensoren gleichbedeutend verwendet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b47a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57934c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pyTorch tensor from python list\n",
    "t=torch.tensor(td)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17425873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13c02d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685de8d",
   "metadata": {},
   "source": [
    "Der Rank eines Tensors entspricht der Länge seiner Shape.(__Hinweis__: python list!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f5c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d27214",
   "metadata": {},
   "source": [
    "##### Reshaping eines Tensors\n",
    "\n",
    "Reshaping verändert die Anordnung/Gruppierung von Daten, jedoch nicht die Daten selbst.\n",
    "\n",
    "__Beispiel__: 6 Datenpunkte ~ Werte\n",
    "\n",
    "Shape 6 x 1: (*Rohdaten*)\n",
    "   - number\n",
    "   - scalar\n",
    "   - array\n",
    "   - vector\n",
    "   - 2d-array\n",
    "   - matrix\n",
    "   \n",
    "Shape 2 x 3: (*Einteilung nach Informatik/Mathematik*)\n",
    "   - number, array, 2d-array\n",
    "   - scalar, vector, matrix\n",
    "\n",
    "Shape 3 x 2: (*Map von Informatik nach Mathematik*)\n",
    "   - number, scalar\n",
    "   - array, vector\n",
    "   - 2d-array, matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddfc7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape t from 3x3 to 1x9 (flatten)\n",
    "t.reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46115892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,9).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f7647",
   "metadata": {},
   "source": [
    "##### Beispiel: Input eines CNN\n",
    "\n",
    "Ein CNN erhält typischerweise einen 4-dimensionalen Tensor als Input.\n",
    "\n",
    "```python\n",
    "len([?,?,?,?])==4\n",
    "```\n",
    "\n",
    "Die Zordnung der Achsen dabei ist __[B,C,H,W]__ mit\n",
    "* B: Batch\n",
    "* C: Channel\n",
    "* H: Height \n",
    "* W: Width\n",
    "\n",
    "Ein Batch aus 3 28x28 Graustufen Bildern wird folglich in einem Tensor mit der Shape \\[3,1,28,28\\] an des CNN übergeben.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb7920",
   "metadata": {},
   "source": [
    "### pyTorch spezifische Tensor-Attribute\n",
    "\n",
    "#### Data Type\n",
    "Das Attribut *dtype* spezifiziert den zugrundeliegenden Datentyp der Elemente des Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d120a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646da93a",
   "metadata": {},
   "source": [
    "#### Device\n",
    "Das Attribut *device* spezifiziert, in welcher PU (CPU oder GPU) die Daten des Tensors allokiert sind. pyTorch ermöglicht die Verwendung mehrerer PUs gleichen Typs. Diese werden durch eindeutige Indizes unterschieden (z.B. 'cuda:2')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4d4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55c425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(t.device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755e90a",
   "metadata": {},
   "source": [
    "#### Stride\n",
    "Der Stride eines Tensors gibt an, wieviele Speicherplätze weiter das nächste Element im Tensor abgelegt ist. Der Stride kann nicht kleiner als die Größe eines Elements des Tensors sein. Entspricht der Stride genau der Elementgröße, so spricht man von einem fortlaufenden (*contiguous*) Tensor.\n",
    "\n",
    "Das Layout eines pyTorch Tensors kann mittel des Attributs *layout* ermittelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0c7d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a0061",
   "metadata": {},
   "source": [
    "### Konstruktion eines Tensors aus Daten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ebcb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd7be2",
   "metadata": {},
   "source": [
    "#### Konstruktion mittels Konstruktor der Klasse Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad24547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(data) # class constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc735f2d",
   "metadata": {},
   "source": [
    "Der Konstruktor der Tensor Klasse erzeugt einen Tensor aus Elementen des Typs *float*, genauer gesagt von Elementen des Typs *default_dtype*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf2df64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype used by Tensor() constructor\n",
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7475b",
   "metadata": {},
   "source": [
    "#### Konstruktion mittels Factory Funktionen\n",
    "\n",
    "Die in pyTorch vorhandenen Factory Functions zur Erzeugung eines Tensors inferieren den Datentyp der Tensorelemente aus den Aufrufparametertypen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2053173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data) # factory function, *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bade68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05889dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(data) # factory function, zero memory-copy, *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31958d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(data) # factory function, zero memory-copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331052a9",
   "metadata": {},
   "source": [
    "Der Datentyp der Tensorelemente kann für alle Factory Funktionen auch händisch festgelegt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e49d4a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([1,2,3]), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49c725",
   "metadata": {},
   "source": [
    "#### Memory: Sharing vs. Copying\n",
    "* Der __Klassenkonstruktor__ und die Factory Function __*torch.tensor()*__ realisieren eine __Copy-by-Value__ Semantik\n",
    "* Die Factory Function __*torch.as_tensor()*__ und die Factory Function __*torch.from_numpy()*__ realisieren eine __Copy-by-Reference__ Semantik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1e65d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "989720f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.Tensor(data)\n",
    "t2=torch.tensor(data)\n",
    "t3=torch.as_tensor(data)\n",
    "t4=torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf9beb",
   "metadata": {},
   "source": [
    "Nun werden die Ausgangsdaten verändert..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e613cade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]=0\n",
    "data[1]=0\n",
    "data[2]=0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1a214",
   "metadata": {},
   "source": [
    "Die beiden Tensoren, die mit Copy-by-Value Semantik erzeugt wurden behalten ihre Originalwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2120e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e99a1",
   "metadata": {},
   "source": [
    "Die beiden Tensoren, die mit Copy-by-Reference Semantik erzeugt wurden weisen die aktualisierten Werte aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe2d18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0])\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8054c",
   "metadata": {},
   "source": [
    "__Anmerkungen__:\n",
    "1. *numpy.ndarray* Objekte werden immer auf der CPU allokiert. Werden Tensoroperationen aber auf der GPU ausgeführt, muss die *torch.as_tensor()* Funktion den CPU-Speicher in die GPU kopieren.\n",
    "2. Das Memory-Sharing von *torch.as_tensor()* funktioniert nicht für built-in Datentypen von Python.\n",
    "3. Die potentielle Performance-Steigerung durch *torch.as_tensor()* wird kaum relevant, wenn der Tensor nur einmalig geladen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb573bd",
   "metadata": {},
   "source": [
    "### Konstruktion eines Tensors ohne Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7053a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3) # Identitätsmatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b45a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba74c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f68f5b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1045, 0.9464, 0.1383],\n",
       "        [0.2302, 0.7624, 0.6178],\n",
       "        [0.7514, 0.0135, 0.5159]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6bc71",
   "metadata": {},
   "source": [
    "### Erzeugung eines Tensors auf der CPU oder GPU\n",
    "\n",
    "pyTorch ermöglicht auf sehr einfache Weise zu entscheiden, ob Berechnungen auf der CPU oder der GPU ausgeführt werden sollen.\n",
    "\n",
    "__Achtung__: Alle Operanden einer Berechnung müssen sich auf der selben PU befinden!\n",
    "\n",
    "### Deklaration der Variable auf der CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67f1e441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.tensor([1,2,3,4,5])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b08ae",
   "metadata": {},
   "source": [
    "### Zuweisung der tensor variable zu einer GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa666656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=t.cuda() # not avail\n",
    "#t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad851b41",
   "metadata": {},
   "source": [
    "## Tensor Operationen\n",
    "\n",
    "Die wichtigsten Tensor Operationen sind\n",
    "* Zugriffsoperationen\n",
    "* Reshaping Operationen\n",
    "* Elementweise Operationen\n",
    "* Reduktionsoperationen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ed3df",
   "metadata": {},
   "source": [
    "### Zugriffsoperationen\n",
    "\n",
    "Zugriffsoperationen sind all jene Funktionen, die den direkten Zugriff auf Elemente des Tensors ermöglichen. Diese sind zum Beispiel der Index Operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791969ed",
   "metadata": {},
   "source": [
    "### Reshaping Operationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89524765",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bd488f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4edbb2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e80ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank\n",
    "len(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f418d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element count\n",
    "torch.tensor(t.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31c160a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element.count\n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e510ae2",
   "metadata": {},
   "source": [
    "#### reshape()\n",
    "Die Reshape Operation verändert die Shape des Tensors, nicht aber die zugrundeliegenden Daten. Deshalb muss __das Produkt aller Achsenlängen immer gleich der Anzahl der Elemente des Tensors__ sein.\n",
    "\n",
    "##### Unveränderter Rang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56d5c288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bec1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2.],\n",
       "        [2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "229a3030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a7af082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 2., 2.],\n",
       "        [2., 2., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2911eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1a159e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(12,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814e07e",
   "metadata": {},
   "source": [
    "##### Veränderter Rang\n",
    "\n",
    "Auch wenn der Rang des Tensors verändert wird, muss das __Produkt der Achsenlängen wieder gleich der Anzahl der Elemente__ sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a5fac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 3.],\n",
       "         [3., 3., 3.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de208f1",
   "metadata": {},
   "source": [
    "#### squeeze() und unsqueeze()\n",
    "\n",
    "* __*squeeze()*__ entfernt alle Achsen mit einer Länge von 1\n",
    "* __*unsqueeze()*__ fügt Achsen mit einer Länge von 1 hinzu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dafb9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# print the original tensor and it's size\n",
    "print(t.reshape(1,12))\n",
    "print(t.reshape(1,12).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7b02ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# print the squeezed tensor and it's size\n",
    "print(t.reshape(1,12).squeeze())\n",
    "print(t.reshape(1,12).squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e3e26d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# print the unsqueezed squeezed tensor and it's size\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0))\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed741bb",
   "metadata": {},
   "source": [
    "##### Beispiel: Flatten\n",
    "\n",
    "Die Flatten Operation wird beispielsweise am Übergang von einem Convolutional Layer zu einem Dense Layer benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60ea02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1,-1) # -1 denotes 'find out yourself!'\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70769171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b054b",
   "metadata": {},
   "source": [
    "#### Concatenation\n",
    "\n",
    "__*cat()*__ verbindet zwei Tensoren. Die Shape des durch die Operation entstehenden neuen Tensors hängt dabei von der Shape der beiden Operanden ab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6572f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define operands a and b\n",
    "a=torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "b=torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c911d",
   "metadata": {},
   "source": [
    "Zeilenweise Kombination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f4f01c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da2c0b",
   "metadata": {},
   "source": [
    "Spaltenweise Kombination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8e381f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad00e1",
   "metadata": {},
   "source": [
    "__*stack()*__ verbindet mehrere Tensoren entlang einer neuen Achse.\n",
    "\n",
    "##### Beispiel: Erstellen eines Batches für ein CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57f60937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define operands t1, t2, t3\n",
    "t1=torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "t2=torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "t3=torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e1047",
   "metadata": {},
   "source": [
    "Verbindung entlang einer neuen Achse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bef3a83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts=torch.stack((t1,t2,t3))\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b2f311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2]],\n",
       "\n",
       "        [[3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa9109",
   "metadata": {},
   "source": [
    "Typische CNNs erwarten als Input einen 4-dimensionalen Tensor (\\[B,C,H,W\\]). Der Tensor ts muss daher mit einer reshape Operation angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c04cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2]]],\n",
       "\n",
       "\n",
       "        [[[3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts=ts.reshape(3,1,4,4) # add a new Axis of length 1 to encapsulate the image data\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a1b37",
   "metadata": {},
   "source": [
    "Der Zugriff auf die einzelnen Komponenten des Tensors erfolgt nun wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a35db345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first image\n",
    "ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbfce684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first channel of the first image\n",
    "ts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b106dd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row of pixels in the first channel of the first image\n",
    "ts[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fc1fe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first pixel value of the first row of pixels in the first channel of the first image\n",
    "ts[0][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b14c62",
   "metadata": {},
   "source": [
    "Um eine Flatten Operation auf die einzelnen Bilder im Batch anzuwenden, ohne den gesamten Batch ebenfalls zu linearisieren aknn die __*flatten()*__ Operation von pyTorch verwendet werden: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbad7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1ed047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef79c40",
   "metadata": {},
   "source": [
    "### Elementweise Operationen\n",
    "\n",
    "Elementweise Operationen sind Operationen zwischen zwei Tensoren, die korrespondierende Elemente dieser Tensoren verknüpfen. Zwei Elemente in den beiden Tensoren werden als korrespondierend bezeichnet, wenn sie die selbe Position innerhalb des jeweiligen Tensors innehaben. Die Position wird durch die Indizes bestimmt, über die auf das Element zugegriffen werden kann.\n",
    "\n",
    "Elementweise Operationen setzen Operanden der selben Shape voraus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "911cdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "], dtype=torch.float32)\n",
    "t2 = torch.tensor([\n",
    "    [9,8],\n",
    "    [7,6]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e010c6e",
   "metadata": {},
   "source": [
    "#### Arithmetische Operationen am Beispiel Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0f85b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10.],\n",
       "        [10., 10.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3f158",
   "metadata": {},
   "source": [
    "##### Addition mit einem Skalar\n",
    "\n",
    "__Problem__: Skalare sind Tensoren mit Rang 0 und haben daher keine Shape!\n",
    "\n",
    "__Lösung__: Skalare werden für elementweise Operationen mit Tensoren mittels einer __*Broadcast*__ Funktion in einen Tensor mit Shape des Operandentensors umgewandelt. Danach kann eine elementweise Addition erfolgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a204ba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this works thanks to broadcast\n",
    "t1+2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9391b",
   "metadata": {},
   "source": [
    "#### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c98c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert scalar 1 to tensor\n",
    "np.broadcast_to(2,t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bfa4ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this addition is equivalent to the one above\n",
    "t1+torch.tensor(\n",
    "    np.broadcast_to(2,t1.shape),\n",
    "    dtype=torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2434c",
   "metadata": {},
   "source": [
    "__Beispiel für zwei Tensoren unterschiedlicher Shape__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "494bec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,1],\n",
    "    [1,1]\n",
    "], dtype=torch.float32)\n",
    "t2 = torch.tensor([\n",
    "    [2,4]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2c357ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f99cfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301586e9",
   "metadata": {},
   "source": [
    "Kann t1+t2 berechnet werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a29c53c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.],\n",
       "       [2., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shpw result of broadcasting\n",
    "np.broadcast_to(t2.numpy(),t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1c0c7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 5.],\n",
       "        [3., 5.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1912b",
   "metadata": {},
   "source": [
    "#### Vergleichsoperationen\n",
    "\n",
    "Vergleichsoperationen sind ebenfalls elementweise Operationen. Sie liefern als Ergebnis einen Tensor der Shape des Operandentensors zurück, der Boolsche Werte für den elementweisen Vergleich enthält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22709962",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [0,5,7],\n",
    "    [6,0,7],\n",
    "    [0,8,0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01c82ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [False,  True, False],\n",
       "        [ True, False,  True]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.eq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0986f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ge(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fcb512c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [ True, False,  True],\n",
       "        [False,  True, False]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.gt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "667d6bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.lt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ecf8c612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False,  True]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.le(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60323946",
   "metadata": {},
   "source": [
    "#### Funktionsoperatoren\n",
    "\n",
    "Auch Funktionen können elementweise auf einen Tensor angewendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17131202",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1, 0, 0],\n",
    "    [0,-1, 0],\n",
    "    [0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21b7c147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  0, -1]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.neg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bbbf0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20220d17",
   "metadata": {},
   "source": [
    "### Reduktionsoperationen\n",
    "\n",
    "Reduktionsoperationen verringern die Anzahl der Elemente innerhalb eines Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f6891f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [0,1,0],\n",
    "    [2,0,2],\n",
    "    [0,3,0]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9a29e",
   "metadata": {},
   "source": [
    "#### sum()\n",
    "__*sum()*__ summiert alle Elemente eines Tensors auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47c602f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62ecc9",
   "metadata": {},
   "source": [
    "Um anstelle eines rank-0 Tensors ein Skalar als Ergebnis zu erhalten kann die item() Funktion des Tensors aufgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95ea1c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360e44c",
   "metadata": {},
   "source": [
    "#### prod()\n",
    "__*prod()*__ multipliziert alle Elemente eines Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f9f46da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.prod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101af1e9",
   "metadata": {},
   "source": [
    "#### mean()\n",
    "__*mean()*__ berechnet den Mittelwert aller Elemente eines Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b9c26ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8889)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e2a5d",
   "metadata": {},
   "source": [
    "#### std()\n",
    "__*std()*__ berechnet die Standardabweichung aller Elemente eines Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f29f13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1667)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1540e16",
   "metadata": {},
   "source": [
    "#### Allgemeine Reduktion (partiell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f18977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ee2226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6., 6.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce along first axis\n",
    "t.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a45919",
   "metadata": {},
   "source": [
    "Diese Reduktion entspricht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d20146d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6., 6.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]+t[1]+t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba2510d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce along second axis\n",
    "t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97725ca8",
   "metadata": {},
   "source": [
    "#### Argmax Reduktion\n",
    "Die Argmax Reduktion reduziert einen Tensor auf die Position seines größten Elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37e8e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,0,0,2],\n",
    "    [0,3,3,0],\n",
    "    [4,0,0,5]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66f3a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the max value of the tensor\n",
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ffc58be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get position of max value in flattened tensor\n",
    "t.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f35d8c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 2., 0., 3., 3., 0., 4., 0., 0., 5.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5c4fde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positions of max value within each column (dim 0)\n",
    "t.argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7423504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2., 3., 5.]),\n",
       "indices=tensor([3, 1, 3]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28a05fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position of max value within each row (dim 1)\n",
    "t.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1d513-a1e1-4464-8e53-f8bde24ca032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c1304-cf22-4b6f-8af8-59c7c46cd8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PPMROB",
   "language": "python",
   "name": "ppmrob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
